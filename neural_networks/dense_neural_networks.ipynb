{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "- MNIST Fashion Dataset included in keras\n",
    "- includes 60,000 images for training and 10,000 images for validation/testing\n",
    "- images are 28x28 pixels (784 input features)\n",
    "- images are greyscale, value is 0 to 255 (0 is black, 255 is white)\n",
    "- labels are the type of clothig (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle Boot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Label names, encoded as 0-9\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Load dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "# split into training and tesing\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data - squish data into the range [0,1]\n",
    "# pixels are in the range 0-255, so just divide by 255\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "Define the architecture of the model\n",
    "\n",
    "Using Sequential - data only propogrates left to right in network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    # Input Layer: Take shape of 28x28 matrix and flatten it into linear input array\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    # Hidden Layer: Dense layer, so every neuron from previous layer is connected - 128 neurons, relu activation function\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # Output Layer: Dense layer, 10 classes for output label, softmax activation (probability distribution for each class)\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model\n",
    "Define the loss function, the optimizer, and the metrics to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',   # Choose the adam algorithm to preform gradient descent\n",
    "    loss='sparse_categorical_crossentropy', # Function to claculate the loss\n",
    "    metrics=['accuracy']    # Keep track of accuracy during training\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "fit the model to the training data\n",
    "- choose the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=1)    # choose 10 epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "- Test the model on the test data\n",
    "- If the testing accuracy is lower than the training accuracy, model may be overfitted\n",
    "- can go back and change hyperparameters (like the number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)   # verbose is how much information to print\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "- predict type of clothing for each image in test dataset (10,000 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)    # probability distribution of each class for each image\n",
    "\n",
    "entry = 0   # entry of images to look at\n",
    "\n",
    "# Print expected label\n",
    "print(class_names[test_labels[entry]])\n",
    "\n",
    "# show image of entry\n",
    "plt.figure()\n",
    "plt.imshow(test_images[entry], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# get the maximum value in the list to get the predicted class - argmax returns index of largest value\n",
    "print(class_names[np.argmax(predictions[entry])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
